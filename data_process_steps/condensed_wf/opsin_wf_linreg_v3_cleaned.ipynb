{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2f4de42",
   "metadata": {},
   "source": [
    "# <font color=green>deepBreaks Applications</font>\n",
    "## Modeling spectral tuning sites of opsin proteins based on amino-acid sequence...  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19f221fe",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5b43e3c",
   "metadata": {},
   "source": [
    "# <font color=red>Step 0: mySQL DB Setup -</font> Script 0\n",
    "## *The following text is a script written in mySQL format. You can copy and paste this directly into a mySQL text file or query window within mySQL workbench.*\n",
    "```\n",
    "DROP DATABASE vizphiz;\n",
    "CREATE DATABASE vizphiz;\n",
    "USE vizphiz;\n",
    "\n",
    "CREATE TABLE lamdamax\n",
    "(\n",
    "id int unsigned not null primary key,\n",
    "genus varchar(50),\n",
    "species varchar(50),\n",
    "celltype varchar(50),\n",
    "cellsubtype varchar(50),\n",
    "lamdamax decimal(9,5),\n",
    "error decimal(9,5),\n",
    "chromophore varchar(50),\n",
    "method varchar(50),\n",
    "stage varchar(50),\n",
    "refid int,\n",
    "notes varchar(1000)\n",
    ");\n",
    "\n",
    "CREATE TABLE heterologous\n",
    "(\n",
    "hetid int unsigned not null primary key,\n",
    "genus  varchar(50),\n",
    "species varchar(50),\n",
    "accession varchar(500),\n",
    "mutations varchar(500),\n",
    "lamdamax decimal(9,5),\n",
    "error decimal(9,5),\n",
    "cellculture varchar(50),\n",
    "purification varchar(50),\n",
    "spectrum varchar(50),\n",
    "sourcetype varchar(50),\n",
    "refid int,\n",
    "notes varchar(1000)\n",
    ");\n",
    "\n",
    "CREATE TABLE links\n",
    "(\n",
    "linkid int unsigned not null primary key,\n",
    "accession varchar(500),\n",
    "maxid int,\n",
    "refid int,\n",
    "evidence varchar(1000)\n",
    ");\n",
    "\n",
    "CREATE TABLE search\n",
    "(\n",
    "searchid int unsigned not null primary key,\n",
    "researcher varchar(50),\n",
    "month int,\n",
    "year int,\n",
    "engine varchar(500),\n",
    "keywords varchar(500)\n",
    ");\n",
    "\n",
    "CREATE TABLE opsins\n",
    "(\n",
    "opsinid int unsigned not null primary key,\n",
    "genefamily varchar(50),\n",
    "genenames varchar(50),\n",
    "genus varchar(50),\n",
    "phylum varchar(25,)\n",
    "species varchar(50),\n",
    "db varchar(50),\n",
    "accession varchar(500),\n",
    "dna varchar(10000),\n",
    "aa varchar(3333),\n",
    "refid int\n",
    ");\n",
    "\n",
    "CREATE TABLE refs\n",
    "(\n",
    "refid int,\n",
    "doilink varchar(100),\n",
    "searchid int\n",
    ");\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neccessary packages to import for data process steps.\n",
    "import mysql\n",
    "import mysql.connector\n",
    "#install mysql-connector-python // NOT mysql-connector\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5778bef",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 0: Data Base Setup -</font> Script 1 - Import heterologous.tsv into mySQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database= \"vizphiz\",\n",
    "  password= \"Geass5566!!\"\n",
    ")\n",
    "\n",
    "#read file for data\n",
    "file1 = open('heterologous.tsv', 'r', encoding=\"utf8\")\n",
    "Lines = file1.readlines()\n",
    "\n",
    "count=0\n",
    "for line in Lines:\n",
    "    columns = line.split(\"\\t\")\n",
    "    print(columns)\n",
    "    mycursor = mydb.cursor()\n",
    "\n",
    "    sql = \"INSERT INTO opsins.heterologous (hetid, genus, species, accession, mutations, lamdamax, error, cellculture, purification, spectrum, sourcetype, refid) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "    val = (columns[0], columns[1], columns[2], columns[3], columns[4], columns[5], columns[6], columns[7], columns[8], columns[9], columns[10], columns[11])\n",
    "    print(sql)\n",
    "    print(val)\n",
    "\n",
    "    mycursor.execute(sql, val)\n",
    "\n",
    "    mydb.commit()\n",
    "\n",
    "    print(mycursor.rowcount, \"record inserted.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31e8500e",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 0: Data Base Setup -</font> Script 2 - Import opsindb.tsv into mySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database= \"vizphiz\",\n",
    "  password= \"Geass5566!!\"\n",
    ")\n",
    "\n",
    "#read file for data\n",
    "file1 = open('opsindb.tsv', 'r')\n",
    "Lines = file1.readlines()\n",
    "\n",
    "count=0\n",
    "for line in Lines:\n",
    "    columns = line.split(\"\\t\")\n",
    "\n",
    "    mycursor = mydb.cursor()\n",
    "\n",
    "    sql = \"INSERT INTO opsins.opsins (opsinid, genefamily, genenames, genus, species, phylum, db, accession, dna, aa, refid) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "    val = (columns[0], columns[1], columns[2], columns[3], columns[4], columns[5], columns[6], columns[7], columns[8], columns[9], columns[10])\n",
    "    print(sql)\n",
    "    print(val)\n",
    "\n",
    "    mycursor.execute(sql, val)\n",
    "\n",
    "    mydb.commit()\n",
    "\n",
    "    print(mycursor.rowcount, \"record inserted.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6c27589",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 1: Extract Data From Vizphiz</font>\n",
    "### Output = 5 different 'versions' // 'splits' of the data. \n",
    "### !Take outputs and run through MAFFT before moving on to STEP2!\n",
    "### Suggested parameters for 'mafft' alignment are...\n",
    "1. Fasta Format (Sorted)\n",
    "\n",
    "2. Strategy = FFT-NS-2 // G-INS-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_output = 'wds.txt'\n",
    "sws_output = 'swd.txt'\n",
    "mws_output = 'mwd.txt'\n",
    "rod_output = 'rod.txt'\n",
    "wd_ni_output = 'wds_ni.txt'\n",
    "nmoc_output = 'nmoc.txt'\n",
    "wh_metadata = 'wds_meta.tsv'\n",
    "sw_metadata = 'sws_meta.tsv'\n",
    "mw_metadata = 'mws_meta.tsv'\n",
    "rh_metadata = 'rod_meta.tsv'\n",
    "wd_ni_metadata = 'wds_ni_meta.tsv'\n",
    "nmoc_metadata = \"nmoc_meta.tsv\"\n",
    "m = 0\n",
    "s = 0\n",
    "l = 0\n",
    "r = 0\n",
    "c = 0\n",
    "z = 0\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database=\"vizphiz\",\n",
    "  password=\"Geass5566!!\"\n",
    ") \n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "sql = \"select DISTINCT o.genus,o.species,o.genefamily,o.accession,h.lamdamax,o.aa,o.phylum from opsins.opsins o, opsins.heterologous h WHERE (o.accession = h.accession AND o.refid = h.refid); \"\n",
    "mycursor.execute(sql)\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "\n",
    "for x in myresult:       \n",
    "#REG-DATA SECTION    \n",
    "  with open(wd_output, 'a') as f:\n",
    "    if m == 0:\n",
    "      f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "    if(x[3]) == \"NM_001014890.2\":\n",
    "      pass\n",
    "    else:\n",
    "      m += 1 \n",
    "      #This makes the fasta format file\n",
    "      seq = \">S\" + str(m)\n",
    "      f.write(seq)\n",
    "      seq2 = str('\\n' + x[5] + '\\n')\n",
    "      f.write(seq2)\n",
    "\n",
    "  with open(wd_ni_output, 'a') as f:\n",
    "  p = re.compile('^Rtc|^BRh[0-3]|Pr[A-Z]|Rh1,Rh3|^IV|^inv')\n",
    "  if (p.match(x[2])):\n",
    "    pass\n",
    "  else:\n",
    "    if c == 0:\n",
    "      f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "    if(x[3]) == \"NM_001014890.2\" or (x[0] == \"Limenitis \" or \"Papilio \"):\n",
    "      pass\n",
    "    else:\n",
    "      c += 1 \n",
    "      #This makes the fasta format file\n",
    "      seq = \">S\" + str(c)\n",
    "      f.write(seq)\n",
    "      seq2 = str('\\n' + x[5] + '\\n')\n",
    "      f.write(seq2)\n",
    "\n",
    "  with open(nmoc_output, 'a') as f:\n",
    "  p = re.compile('[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "  if (p.search(x[3]) or \"-\" in x[3]):\n",
    "    pass\n",
    "  else:\n",
    "    if z == 0:\n",
    "      f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "    if(x[3]) == \"NM_001014890.2\":\n",
    "      pass\n",
    "    else:\n",
    "      z += 1 \n",
    "      #This makes the fasta format file\n",
    "      seq = \">S\" + str(z)\n",
    "      f.write(seq)\n",
    "      seq2 = str('\\n' + x[5] + '\\n')\n",
    "      f.write(seq2)\n",
    "\n",
    "  with open(sws_output, 'a') as f:\n",
    "  p = re.compile('^SWS|^UVS')\n",
    "  if p.match(x[2]):\n",
    "    s+=1\n",
    "    if s == 1:\n",
    "      f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")  \n",
    "  #This makes the fasta format file\n",
    "    seq = \">S\" + str(s)\n",
    "    f.write(seq)\n",
    "    seq2 = str('\\n' + x[5] + '\\n')\n",
    "    f.write(seq2)\n",
    "\n",
    "  with open(mws_output, 'a') as f:\n",
    "  p = re.compile('^MWS|^LWS')\n",
    "  if p.match(x[2]):\n",
    "    l+=1\n",
    "    if l == 1:\n",
    "      f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "    #This makes the fasta format file\n",
    "    seq = \">S\" + str(l)\n",
    "    f.write(seq)\n",
    "    seq2 = str('\\n' + x[5] + '\\n')\n",
    "    f.write(seq2)\n",
    "\n",
    "  with open(rod_output, 'a') as f:\n",
    "  p = re.compile('Rh[0-2]|exoRh')\n",
    "  if p.match(x[2]):\n",
    "    if r == 0:\n",
    "      f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "    if(x[3]) == \"NM_001014890.2\" or (x[0] == \"Limenitis \" or \"Papilio \"):\n",
    "      pass\n",
    "    else:\n",
    "      r+=1\n",
    "      #This makes the fasta format file\n",
    "      seq = \">S\" + str(r)\n",
    "      f.write(seq)\n",
    "      seq2 = str('\\n' + x[5] + '\\n')\n",
    "      f.write(seq2)\n",
    "\n",
    "#METADATA SECTION\n",
    "  with open(wh_metadata, 'a') as g:\n",
    "  #This makes the metadata formatted for a linear regression model.\n",
    "  if m == 1:\n",
    "    g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")  \n",
    "    g.write(\"Bovine\\t500.000\\tBos_taurus\\tRh1\\tNM_001014890\\n\")\n",
    "  if(x[3]) == \"NM_001014890.2\":\n",
    "    pass\n",
    "  else:        \n",
    "    md =  str(\"S\" + str(m) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "    g.write(md)\n",
    "\n",
    "  with open(wd_ni_metadata, 'a') as g:\n",
    "  p = re.compile('^Rtc|^BRh[0-3]|Pr[A-Z]|Rh1,Rh3|^IV|^inv')\n",
    "  if p.match(x[2]):\n",
    "    pass\n",
    "  #This makes the metadata formatted for a linear regression model.\n",
    "  else:\n",
    "    if c == 1:\n",
    "      g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")\n",
    "      g.write(\"Bovine\\t500.0000\\tBos_taurus\\tRh1\\tNM_001014890\\n\")\n",
    "    if(x[3]) == \"NM_001014890.2\" or (x[0] == \"Limenitis \" or \"Papilio \"):\n",
    "      pass\n",
    "    else:  \n",
    "      md =  str(\"S\" + str(c) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "      g.write(md)\n",
    "\n",
    "  with open(sw_metadata, 'a') as g:\n",
    "  #This makes the metadata formatted for a linear regression model.\n",
    "  p = re.compile('^SWS|^UVS')\n",
    "  if p.match(x[2]):\n",
    "    if s == 1:\n",
    "      g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")\n",
    "      g.write(\"Bovine\\t500.0000\\tBos_taurus\\tRh1\\tNM_001014890\\n\")  \n",
    "    md =  str(\"S\" + str(s) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "    g.write(md)\n",
    "\n",
    "  with open(mw_metadata, 'a') as g:\n",
    "  #This makes the metadata formatted for a linear regression model.\n",
    "  p = re.compile('^MWS|^LWS')\n",
    "  if p.match(x[2]):\n",
    "    if l == 1:\n",
    "      g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")  \n",
    "      g.write(\"Bovine\\t500.0000\\tBos_taurus\\tRh1\\tNM_001014890\\n\")  \n",
    "    md =  str(\"S\" + str(l) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "    g.write(md)\n",
    "\n",
    "  with open(rh_metadata, 'a') as g:\n",
    "  #This makes the metadata formatted for a linear regression model.\n",
    "  p = re.compile('Rh[0-3]|exoRh')\n",
    "  if p.match(x[2]):\n",
    "    if r == 1:\n",
    "      g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")\n",
    "      g.write(\"Bovine\\t500.0000\\tBos_taurus\\tRh1\\tNM_001014890\\n\")\n",
    "    if(x[3]) == \"NM_001014890.2\" or (x[0] == \"Limenitis \" or \"Papilio \"):\n",
    "      pass\n",
    "    else:  \n",
    "      md =  str(\"S\" + str(r) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "      g.write(md)\n",
    "\n",
    "  with open(nmoc_metadata, 'a') as g:\n",
    "  p = re.compile('[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T][0-9]+[G,A,L,M,F,W,K,Q,E,S,P,V,I,C,Y,H,R,N,D,T]')\n",
    "  if (p.search(x[3]) or \"-\" in x[3]):\n",
    "    pass\n",
    "  else:\n",
    "    if z == 1:\n",
    "      g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")  \n",
    "      g.write(\"Bovine\\t500.0000\\tBos_taurus\\tRh1\\tNM_001014890\\n\")\n",
    "    if(x[3]) == \"NM_001014890.2\" or (x[4] == 0):\n",
    "      pass\n",
    "    else:        \n",
    "      md =  str(\"S\" + str(z) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "      g.write(md)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "261d0aca",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 2: Format Alignments for 'deepBreaks'</font>\n",
    "## REMINDER - Take outputs from STEP 1 and run through MAFFT before moving on to STEP2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e914c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter list of aligned text files here.\n",
    "inputs = ['wds2_aligned.txt']\n",
    "# inputs = ['wds_aligned.txt','wds_ni_aligned.txt','rod_aligned.txt','nmoc_aligned.txt']\n",
    "##enter list of names for desired formatted fasta files here.\n",
    "output = ['wds2_fmt_msp.fasta']\n",
    "# output = ['wds_fmt.fasta','wds_ni_fmt.fasta','rod_fmt.fasta','nmoc_fmt.fasta']\n",
    "i=0\n",
    "k = 0\n",
    "for files in inputs:\n",
    "    lines = open(inputs[i]).readlines()\n",
    "    file = open(output[i], 'a+')\n",
    "    #line_count = len(lines)\n",
    "    #tab_entry = \"\"\n",
    "    #call = input(\"How Many Lines Per Alignment?: \")\n",
    "    #count = int(call)\n",
    "    #loop = range(int(count))\n",
    "    m=0\n",
    "    for line in lines:\n",
    "        snip = str(lines[k])\n",
    "        if '>' in snip:\n",
    "            if m == 0:\n",
    "                m+=1\n",
    "            else:\n",
    "                file.write(\"\\n\")\n",
    "            file.write(snip)\n",
    "        else:\n",
    "            entry = \"\"\n",
    "            entry = str(snip.replace(\"\\n\",\"\"))\n",
    "            file.write(entry)\n",
    "        k+=1\n",
    "    k = 0\n",
    "    i+=1\n",
    "    file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2969791",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 3: deepBreaks</font>\n",
    "## THIS IS A LONG SECTION! \n",
    "### STEP 4 doesn't start until Cell 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eed2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing deepBreaks libraries \n",
    "from deepBreaks.utils import get_models, get_scores, get_params, make_pipeline\n",
    "from deepBreaks.preprocessing import MisCare, ConstantCare, URareCare, CustomOneHotEncoder\n",
    "from deepBreaks.preprocessing import FeatureSelection, CollinearCare\n",
    "from deepBreaks.preprocessing import read_data\n",
    "from deepBreaks.models import model_compare_cv, finalize_top, importance_from_pipe, mean_importance, summarize_results\n",
    "from deepBreaks.visualization import plot_scatter, dp_plot, plot_imp_model, plot_imp_all\n",
    "import warnings\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f084f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining user params, file pathes, analysis type\n",
    "\n",
    "# path to sequences\n",
    "seqFileName = 'wds2_fmt_msp.fasta' \n",
    "\n",
    "# path to metadata\n",
    "metaDataFileName = 'wds_meta.tsv' \n",
    "\n",
    "# name of the phenotype\n",
    "mt = 'Lambda_Max'\n",
    "\n",
    "# type of the sequences\n",
    "seq_type = 'aa'\n",
    "\n",
    "# type of the analysis if it is a classification model, then we put cl instead of reg\n",
    "ana_type = 'reg' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d592e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a unique directory for saving the reports of the analysis\n",
    "print('direcory preparation')\n",
    "dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "seqFile = seqFileName.split('.')[0]\n",
    "report_dir = str(seqFile +'_' + mt + '_' + dt_label)\n",
    "os.makedirs(report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0ba03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print('reading meta-data')\n",
    "# importing metadata\n",
    "meta_data = read_data(metaDataFileName, seq_type = None, is_main=False)\n",
    "\n",
    "# importing sequences data\n",
    "print('reading fasta file')\n",
    "tr = read_data(seqFileName, seq_type = seq_type, is_main=True, gap_threshold=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start here with removing the bottom ~25 sequences \n",
    "msp = tr.iloc[856:].copy()\n",
    "msp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tr = tr.merge(meta_data.loc[:, mt],  left_index=True, right_index=True)\n",
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed894d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_n = 50\n",
    "n = 0\n",
    "while n < 1:\n",
    "    drop_indices = np.random.choice(tr.index, sample_n, replace=False)\n",
    "    #print(drop_indices)\n",
    "    #drop_indices = np.append(drop_indices,['Bovine'])\n",
    "    #print(drop_indices)\n",
    "    if 'Bovine' in drop_indices:\n",
    "        pass\n",
    "    else:\n",
    "        n+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77544a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen = tr.loc[drop_indices].copy()\n",
    "umd = unseen.loc[:, mt].values\n",
    "\n",
    "unseen.drop(mt, axis=1, inplace=True)\n",
    "tr = tr.drop(drop_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b41bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_test = meta_data.loc[drop_indices].copy()\n",
    "base_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tr.loc[:, mt].values\n",
    "tr.drop(mt, axis=1, inplace=True)\n",
    "print('Shape of data is: ', tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bovine = tr.loc['Bovine'].copy()\n",
    "\n",
    "#print(bovine)\n",
    "\n",
    "bovine.to_csv(path_or_buf= f'{report_dir}/bovine.csv',index = True,mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33505136",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69979653",
   "metadata": {},
   "source": [
    "**Attention**: metadata and sequences data should have the names as their row names and for each sequence their must be a value in the meta data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('metadata looks like this:')\n",
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sequence data looks like this:')\n",
    "tr.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "140f567b",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "In this step, we do all these steps:\n",
    "1. dropping columns with a number of missing values above a certain threshold  \n",
    "2. dropping zero entropy columns  \n",
    "3. imputing missing values with the mode of that column  \n",
    "4. replacing cases with a frequency below a threshold (default 1.5%) with the mode of that column\n",
    "5. dropping zero entropy columns\n",
    "6. use statistical tests (each position against the phenotype) and drop columns with p-values below a threshold (default 0.25)\n",
    "7. one-hot encode the remaining columns\n",
    "8. calculate the pair-wise distance matrix for all of the columns\n",
    "9. use the distance matrix for DBSCAN and cluster the correlated positions together\n",
    "10. keep only one column (closes to center of each cluster) for each group and drop the rest from the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pipeline = make_pipeline(\n",
    "    steps=[\n",
    "        ('mc', MisCare(missing_threshold=0.05)),\n",
    "        ('cc', ConstantCare()),\n",
    "        ('ur', URareCare(threshold=0.025)),\n",
    "        ('cc2', ConstantCare()),\n",
    "        ('one_hot', CustomOneHotEncoder()),\n",
    "        ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=False)),\n",
    "        ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.05, keep=False))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "report, top = model_compare_cv(X=tr, y=y, preprocess_pipe=prep_pipeline,\n",
    "                               models_dict=get_models(ana_type=ana_type),\n",
    "                               scoring=get_scores(ana_type=ana_type),\n",
    "                               report_dir=report_dir,\n",
    "                               cv=12, ana_type=ana_type, cache_dir=report_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af902297",
   "metadata": {},
   "source": [
    "MAE = Mean Absolute Error\n",
    "\n",
    "MSE = Mean Squared Error\n",
    "\n",
    "RMSE = Rooted Mean Square Error\n",
    "\n",
    "MAPE = Mean Absolute % Error - the average magnitude of error produced by a model, or how far off predictions are on average. A MAPE value of 20% means that the average absolute percentage difference between the predictions and the actuals is 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f4a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f365ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hold = tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda54a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pipeline = make_pipeline(\n",
    "    steps=[\n",
    "        ('mc', MisCare(missing_threshold=0.05)),\n",
    "        ('cc', ConstantCare()),\n",
    "        ('ur', URareCare(threshold=0.025)),\n",
    "        ('cc2', ConstantCare()),\n",
    "        ('one_hot', CustomOneHotEncoder()),\n",
    "        ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=True)),\n",
    "        ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.05, keep=True))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df108475",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_top = []\n",
    "for model in top:\n",
    "    modified_top.append(make_pipeline(steps=[('prep', prep_pipeline), model.steps[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7005603",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_top[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "top = finalize_top(X=tr, y=y, top_models=modified_top, grid_param=get_params(),report_dir=report_dir, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sr = summarize_results(top_models=top, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bce71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot = plot_scatter(summary_result=sr, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_imp = mean_importance(top, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e644ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_plot(importance=mean_imp,imp_col='mean', model_name='mean', report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ed0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = prep_pipeline[:4].fit_transform(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in top:\n",
    "    model_name = model.steps[-1][0]\n",
    "    dp_plot(importance=importance_from_pipe(model),\n",
    "            imp_col='standard_value',\n",
    "            model_name = model_name, report_dir=report_dir)\n",
    "    \n",
    "    plot_imp_model(importance=importance_from_pipe(model), \n",
    "               X_train=tr, y_train=y, model_name=model_name,\n",
    "                   meta_var='meta', model_type=ana_type, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = plot_imp_all(final_models=top,\n",
    "                  X_train=tr, y_train=y,\n",
    "                  model_type = ana_type,\n",
    "                  report_dir=report_dir, max_plots=100,\n",
    "                  figsize=(2.5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepBreaks.utils import load_obj\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "load_rf = load_obj(report_dir + '/lgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559660c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = load_rf.predict(unseen)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0462473",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_test['Prediction'] = predictions\n",
    "base_test['Difference'] = base_test['Prediction'] - base_test['Lambda_Max']\n",
    "base_test = base_test[['Species', 'Opsin_Family', 'Accession','Lambda_Max','Prediction','Difference']]\n",
    "\n",
    "base_test.to_csv(path_or_buf= f'{report_dir}/basetest_results.csv',index = 'Feature',mode=\"w\")\n",
    "\n",
    "base_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "\n",
    "plt.scatter(umd, predictions, c=predictions, ec = 'k', edgecolors='k', s = 35)\n",
    "plt.plot(umd, umd, c = 'k', linewidth = '1.0', ls = '--', dashes = (1,3))\n",
    "plt.xlabel('Known $位_{max}$ (nm)')\n",
    "plt.ylabel('Predicted $位_{max}$ (nm)')\n",
    "plt.annotate(f\"$R^2$ = {load_rf.score(unseen, umd):.3f}\",(350, 500), fontsize = 20, c = 'k')\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "\n",
    "\n",
    "#start, end = plt.get_xlim()\n",
    "#plt.xaxis.set_ticks(np.arange(start, end, 25))\n",
    "fileout = f'{report_dir}/50_hetero_dp.pdf'\n",
    "plt.savefig(fileout)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170bc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_testing__report = f'{report_dir}/model_testing report.tsv'\n",
    "\n",
    "base_rsq = load_rf.score(unseen, umd)\n",
    "print(base_rsq)\n",
    "\n",
    "base_mae = mean_absolute_error(predictions,umd)\n",
    "print(base_mae)\n",
    "\n",
    "base_mape = mean_absolute_percentage_error(predictions,umd)\n",
    "print(base_mape)\n",
    "\n",
    "base_sqe = mean_squared_error(predictions,umd)\n",
    "print(base_sqe)\n",
    "\n",
    "base_rsqe = mean_squared_error(predictions,umd, squared = False)\n",
    "print(base_rsqe)\n",
    "\n",
    "with open(model_testing__report , 'w') as f:\n",
    "    f.write(f'Base Model R^2\\tBase Model MAE\\tBase Model MAPE\\tBase Model SQE\\tBase Model RSQE\\n')\n",
    "    f.write(f'{str(base_rsq)}\\t{str(base_mae)}\\t{str(base_mape)}\\t{str(base_sqe)}\\t{str(base_rsqe)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e5a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "msp_predictions = load_rf.predict(msp)\n",
    "print(msp_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = \"erg_msp_meta.tsv\"\n",
    "msp_meta = pd.read_csv(meta, sep=\"\\t\", index_col = False)\n",
    "msp_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c6109",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax_msp = (msp_meta['Lambda_Max'])\n",
    "lm = []\n",
    "for i in lmax_msp:\n",
    "    lm.append(float(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be719750",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Species','Accession','Lambda_Max','Predicted','Differnce']\n",
    "msp_test = pd.DataFrame(index=msp.index, columns = columns)\n",
    "msp_test['Predicted'] = msp_predictions\n",
    "msp_test['Species'][0:31] = msp_meta['Species']\n",
    "msp_test['Accession'][0:31] = msp_meta['Accession']\n",
    "\n",
    "msp_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msp_test['Lambda_Max'][0:31] = lm\n",
    "msp_test['Differnce'] = msp_test['Predicted'] - msp_test['Lambda_Max']\n",
    "msp_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b8d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "msp_test.to_csv(path_or_buf= f'{report_dir}/msp_test_results.csv',index = 'Feature',mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0734df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(msp_test['Predicted'][0:31], msp_test['Lambda_Max'][0:31])\n",
    "print(mae)\n",
    "msp_rsq = load_rf.score(msp[0:31], msp_test['Lambda_Max'][0:31])\n",
    "print(msp_rsq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfc4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "\n",
    "plt.scatter(msp_test['Lambda_Max'][0:31], msp_predictions[0:31], c=msp_predictions[0:31], ec = 'k', edgecolors='k', s = 35)\n",
    "plt.plot(msp_test['Lambda_Max'][0:31], msp_test['Lambda_Max'][0:31], c = 'k', linewidth = '1.0', ls = '--', dashes = (1,3))\n",
    "plt.xlabel('Known $位_{max}$ (nm)')\n",
    "plt.ylabel('Predicted $位_{max}$ (nm)')\n",
    "plt.annotate(f\"$R^2$ = {load_rf.score(msp[0:31], msp_test['Lambda_Max'][0:31]):.3f}\",(325, 535), fontsize = 20, c = 'k')\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "\n",
    "\n",
    "#start, end = plt.get_xlim()\n",
    "#plt.xaxis.set_ticks(np.arange(start, end, 25))\n",
    "fileout = f'{report_dir}/31_msp_dp.pdf'\n",
    "plt.savefig(fileout)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213453b9",
   "metadata": {},
   "source": [
    "Below is just a way for me to properly format test data for previously trained models using the base training data... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f956d2a",
   "metadata": {},
   "source": [
    "# importing deepBreaks libraries \n",
    "from deepBreaks.utils import get_models, get_scores, get_params, make_pipeline\n",
    "from deepBreaks.preprocessing import MisCare, ConstantCare, URareCare, CustomOneHotEncoder\n",
    "from deepBreaks.preprocessing import FeatureSelection, CollinearCare\n",
    "from deepBreaks.preprocessing import read_data\n",
    "from deepBreaks.models import model_compare_cv, finalize_top, importance_from_pipe, mean_importance, summarize_results\n",
    "from deepBreaks.visualization import plot_scatter, dp_plot, plot_imp_model, plot_imp_all\n",
    "import warnings\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# defining user params, file pathes, analysis type\n",
    "\n",
    "# path to sequences\n",
    "seqFileName = 'wds_fmt_msp.fasta' \n",
    "\n",
    "# path to metadata\n",
    "metaDataFileName = 'wds_meta.tsv' \n",
    "\n",
    "# name of the phenotype\n",
    "mt = 'Lambda_Max'\n",
    "\n",
    "# type of the sequences\n",
    "seq_type = 'aa'\n",
    "\n",
    "# type of the analysis if it is a classification model, then we put cl instead of reg\n",
    "ana_type = 'reg' \n",
    "\n",
    "# making a unique directory for saving the reports of the analysis\n",
    "print('direcory preparation')\n",
    "dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "seqFile = seqFileName.split('.')[0]\n",
    "report_dir = str(seqFile +'_' + mt + '_' + dt_label)\n",
    "os.makedirs(report_dir)\n",
    "\n",
    "print('reading meta-data')\n",
    "# importing metadata\n",
    "meta_data = read_data(metaDataFileName, seq_type = None, is_main=False)\n",
    "\n",
    "# importing sequences data\n",
    "print('reading fasta file')\n",
    "tr = read_data(seqFileName, seq_type = seq_type, is_main=True, gap_threshold=0.6)\n",
    "\n",
    "#start here with removing the bottom ~25 sequences \n",
    "msp = tr.iloc[856:].copy()\n",
    "msp.head()\n",
    "\n",
    "tr = tr.merge(meta_data.loc[:, mt],  left_index=True, right_index=True)\n",
    "tr.shape\n",
    "\n",
    "sample_n = 50\n",
    "n = 0\n",
    "while n < 1:\n",
    "    drop_indices = np.random.choice(tr.index, sample_n, replace=False)\n",
    "    #print(drop_indices)\n",
    "    #drop_indices = np.append(drop_indices,['Bovine'])\n",
    "    #print(drop_indices)\n",
    "    if 'Bovine' in drop_indices:\n",
    "        pass\n",
    "    else:\n",
    "        n+=1\n",
    "\n",
    "unseen = tr.loc[drop_indices].copy()\n",
    "umd = unseen.loc[:, mt].values\n",
    "\n",
    "unseen.drop(mt, axis=1, inplace=True)\n",
    "tr = tr.drop(drop_indices)\n",
    "\n",
    "y = tr.loc[:, mt].values\n",
    "tr.drop(mt, axis=1, inplace=True)\n",
    "print('Shape of data is: ', tr.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08805113",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 4: Translate Candidate STSs</font> \n",
    "## Optional step IF running the classifier model, but could still be useful.\n",
    "### To find CSTSs, got to the deepBreaks output folder and find the excel sheet 'avg_top_models_feature_importance'\n",
    "### Sort the top model's feature importance column by 'largest-to-smallest' and take x# of those positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 4: Translate Candidate STSs \n",
    "#Optional step IF running the classifier model, but could still be useful.\n",
    "#To find CSTSs, got to the deepBreaks output folder and find the excel sheet 'avg_top_models_feature_importance'\n",
    "#Sort the top model's feature importance column by 'largest-to-smallest' and take x# of those positions.\n",
    "m = 0\n",
    "tm = ''\n",
    "k=0\n",
    "gaps=0\n",
    "#import importance_report.csv from report_dir\n",
    "true_pos = []\n",
    "aa = []\n",
    "tmd = []\n",
    "\n",
    "df = pd.read_csv(f'{report_dir}\\importance_report.csv')\n",
    "\n",
    "#take the list of important sites and translate them to the bovine standard equivalent, we do this by taking the site number and subtracting the number of '-' between the start of the sequence and the desired site. \n",
    "for rows in bovine.values:  \n",
    "    rows = str(rows)\n",
    "    print(rows)\n",
    "    if rows == 'nan':\n",
    "    #We want to write the 'true_pos', 'aa', and 'TMD' to the 'importance_report' csv file\n",
    "        gaps += 1\n",
    "        k += 1\n",
    "        true_pos.append('NA')\n",
    "        aa.append('-')\n",
    "        tmd.append('NA')\n",
    "    else:\n",
    "        #print(\"The number of gaps is \" + str(gaps))\n",
    "        k+=1\n",
    "        trans_site = k - gaps\n",
    "\n",
    "        if trans_site in range(39,66):\n",
    "            tm = '1'\n",
    "        elif trans_site in range(3,38):\n",
    "            tm = 'N-Termina'\n",
    "        elif trans_site in range(72,100):\n",
    "            tm = '2'\n",
    "        elif trans_site in range(110,141):\n",
    "            tm = '3'\n",
    "        elif trans_site in range(151,174):\n",
    "            tm = '4'\n",
    "        elif trans_site in range(200,231):\n",
    "            tm = '5'\n",
    "        elif trans_site in range(245,276):\n",
    "            tm = '6'\n",
    "        elif trans_site in range(285,311):\n",
    "            tm = '7'\n",
    "        else:\n",
    "            tm = 'NA'\n",
    "        \n",
    "        true_pos.append(str(trans_site))\n",
    "        aa.append(rows)\n",
    "        tmd.append(tm)\n",
    "true_pos.pop()\n",
    "aa.pop()\n",
    "tmd.pop()\n",
    "\n",
    "df['true_position'] = true_pos\n",
    "df['TMD'] = tmd\n",
    "df['amino_acid'] = aa\n",
    "\n",
    "df.to_csv(path_or_buf= os.path.join(report_dir,r'importance_report.csv'),index = 'Feature',mode=\"w\")\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepBreaks_altenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1566c31c90cd32f196ccfa15812cd8e8608767ea4549b0419bac2fea141e189a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
