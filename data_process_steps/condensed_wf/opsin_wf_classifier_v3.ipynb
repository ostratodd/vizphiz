{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "846ccd62",
   "metadata": {},
   "source": [
    "# <font color=green>deepBreaks Applications</font>\n",
    "## Predicting the Phenotype of an Opsin From its Amino Acid Sequence...\n",
    "## This Version of our pipeline uses deepBreaks v. 1.1.0! \n",
    "[Env name == deepBreaks]\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73fe141f",
   "metadata": {},
   "source": [
    "# <font color=red>Step 0: mySQL DB Setup -</font> Script 0\n",
    "## *The following text is a script written in mySQL format. You can copy and paste this directly into a mySQL text file or query window within mySQL workbench.*\n",
    "```\n",
    "DROP DATABASE vizphiz;\n",
    "CREATE DATABASE vizphiz;\n",
    "USE vizphiz;\n",
    "\n",
    "CREATE TABLE lamdamax\n",
    "(\n",
    "id int unsigned not null primary key,\n",
    "genus varchar(50),\n",
    "species varchar(50),\n",
    "celltype varchar(50),\n",
    "cellsubtype varchar(50),\n",
    "lamdamax decimal(9,5),\n",
    "error decimal(9,5),\n",
    "chromophore varchar(50),\n",
    "method varchar(50),\n",
    "stage varchar(50),\n",
    "refid int,\n",
    "notes varchar(1000)\n",
    ");\n",
    "\n",
    "CREATE TABLE heterologous\n",
    "(\n",
    "hetid int unsigned not null primary key,\n",
    "genus  varchar(50),\n",
    "species varchar(50),\n",
    "accession varchar(500),\n",
    "mutations varchar(500),\n",
    "lamdamax decimal(9,5),\n",
    "error decimal(9,5),\n",
    "cellculture varchar(50),\n",
    "purification varchar(50),\n",
    "spectrum varchar(50),\n",
    "sourcetype varchar(50),\n",
    "refid int,\n",
    "notes varchar(1000)\n",
    ");\n",
    "\n",
    "CREATE TABLE links\n",
    "(\n",
    "linkid int unsigned not null primary key,\n",
    "accession varchar(500),\n",
    "maxid int,\n",
    "refid int,\n",
    "evidence varchar(1000)\n",
    ");\n",
    "\n",
    "CREATE TABLE search\n",
    "(\n",
    "searchid int unsigned not null primary key,\n",
    "researcher varchar(50),\n",
    "month int,\n",
    "year int,\n",
    "engine varchar(500),\n",
    "keywords varchar(500)\n",
    ");\n",
    "\n",
    "CREATE TABLE opsins\n",
    "(\n",
    "opsinid int unsigned not null primary key,\n",
    "genefamily varchar(50),\n",
    "genenames varchar(50),\n",
    "genus varchar(50),\n",
    "species varchar(50),\n",
    "db varchar(50),\n",
    "accession varchar(500),\n",
    "dna varchar(10000),\n",
    "aa varchar(3333),\n",
    "refid int\n",
    ");\n",
    "\n",
    "CREATE TABLE refs\n",
    "(\n",
    "refid int,\n",
    "doilink varchar(100),\n",
    "searchid int\n",
    ");\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neccessary packages to import for data process steps.\n",
    "import mysql\n",
    "#install mysql-connector-python // NOT mysql-connector\n",
    "import mysql.connector\n",
    "import argparse\n",
    "import re\n",
    "import pandas as pd\n",
    "import jenkspy \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "718547ad",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 0: Data Base Setup -</font> Script 1 - Import heterologous.tsv into mySQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aac0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database= \"vizphiz\",\n",
    "  password= \"Geass5566!!\"\n",
    ")\n",
    "\n",
    "#read file for data\n",
    "file1 = open('heterologous.tsv', 'r', encoding=\"utf8\")\n",
    "Lines = file1.readlines()\n",
    "\n",
    "count=0\n",
    "for line in Lines:\n",
    "    columns = line.split(\"\\t\")\n",
    "    print(columns)\n",
    "    mycursor = mydb.cursor()\n",
    "\n",
    "    sql = \"INSERT INTO opsins.heterologous (hetid, genus, species, accession, mutations, lamdamax, error, cellculture, purification, spectrum, sourcetype, refid) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "    val = (columns[0], columns[1], columns[2], columns[3], columns[4], columns[5], columns[6], columns[7], columns[8], columns[9], columns[10], columns[12])\n",
    "    print(sql)\n",
    "    print(val)\n",
    "\n",
    "    mycursor.execute(sql, val)\n",
    "\n",
    "    mydb.commit()\n",
    "\n",
    "    print(mycursor.rowcount, \"record inserted.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37f09764",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 0: Data Base Setup -</font> Script 2 - Import opsindb.tsv into mySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14fda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database= \"vizphiz\",\n",
    "  password= \"Geass5566!!\"\n",
    ")\n",
    "\n",
    "#read file for data\n",
    "file1 = open('opsindb.tsv', 'r')\n",
    "Lines = file1.readlines()\n",
    "\n",
    "count=0\n",
    "for line in Lines:\n",
    "    columns = line.split(\"\\t\")\n",
    "\n",
    "    mycursor = mydb.cursor()\n",
    "\n",
    "    sql = \"INSERT INTO opsins.opsins (opsinid, genefamily, genenames, genus, species, db, accession, dna, aa, refid) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "    val = (columns[0], columns[1], columns[2], columns[3], columns[4], columns[5], columns[6], columns[7], columns[8], columns[9])\n",
    "    print(sql)\n",
    "    print(val)\n",
    "\n",
    "    mycursor.execute(sql, val)\n",
    "\n",
    "    mydb.commit()\n",
    "\n",
    "    print(mycursor.rowcount, \"record inserted.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ed91ad5",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 1: Extract Data From Vizphiz</font>\n",
    "### Output = 5 different 'versions' // 'splits' of the data. \n",
    "### !Take outputs and run through MAFFT before moving on to STEP2!\n",
    "### Suggested parameters for 'mafft' alignment are...\n",
    "1. Fasta Format (Input Order)\n",
    "\n",
    "2. Strategy = FFT-NS-2 // G-INS-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = re.compile('^Rtc|^BRh[0-3]|Pr[A-Z]|Rh1,Rh3|^IV|^inv')\n",
    "rod = re.compile('Rh[0-2]|exoRh')\n",
    "d = re.compile(\"^NM_001014890.2$|^NM_001014890$\")\n",
    "iec = re.compile(\"Limenitis|Papilio\")\n",
    "\n",
    "\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database=\"vizphiz\",\n",
    "  password=\"Geass5566!!\"\n",
    ") \n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "sql = \"select DISTINCT o.genus,o.species,o.genefamily,o.accession,h.lamdamax, o.aa from opsins.opsins o, opsins.heterologous h WHERE (o.accession = h.accession AND o.refid = h.refid); \"\n",
    "mycursor.execute(sql)\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "props = [\"LambdaMax\"]\n",
    "wds_max = []\n",
    "wds_ni_max = []\n",
    "rod_max = []\n",
    "\n",
    "for x in myresult:\n",
    "  \n",
    "  wds_max.append(float(x[4]))\n",
    "\n",
    "  if (inv.match(x[2]) or iec.match(x[0])):\n",
    "    pass\n",
    "  else:  \n",
    "    wds_ni_max.append(float(x[4]))\n",
    "\n",
    "  if rod.match(x[2]):\n",
    "    if (inv.match(x[2]) or iec.match(x[0])):\n",
    "       pass\n",
    "    else: \n",
    "      rod_max.append(float(x[4]))\n",
    "\n",
    "\n",
    "wds_hist_df = pd.DataFrame(columns=props, data=wds_max)\n",
    "wds_ni_hist_df = pd.DataFrame(columns=props, data=wds_ni_max)\n",
    "rod_hist_df = pd.DataFrame(columns=props, data=rod_max)\n",
    "hist_list = [wds_hist_df, wds_ni_hist_df, rod_hist_df]\n",
    "\n",
    "print(hist_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "wds_class_list = []\n",
    "wds_ni_class_list = []\n",
    "rod_class_list = []\n",
    "\n",
    "for hist_df in hist_list:\n",
    "    five = pd.qcut(hist_df['LambdaMax'], q=5, precision=1, labels=False, retbins=True)\n",
    "    fiv_list = five[1]\n",
    "    print(five[1])\n",
    "    hist_df['bin_qcut5'] = pd.qcut(hist_df['LambdaMax'], q=5, precision=1, labels=False, retbins = False)\n",
    "    plt.hist(hist_df['bin_qcut5'], bins=5)\n",
    "    plt.show()\n",
    "\n",
    "    ten = pd.qcut(hist_df['LambdaMax'], q=10, precision=1, labels=False, retbins=True)\n",
    "    ten_list = ten[1]\n",
    "    print(ten[1])\n",
    "    hist_df['bin_qcut10'] = pd.qcut(hist_df['LambdaMax'], q=10, precision=1, labels=False, retbins = False)\n",
    "    plt.hist(hist_df['bin_qcut10'], bins=10)\n",
    "    plt.show()\n",
    "\n",
    "    fifteen = pd.qcut(hist_df['LambdaMax'], q=15, precision=1, labels=False, retbins=True)\n",
    "    fif_list = fifteen[1]\n",
    "    print(fifteen[1])\n",
    "    hist_df['bin_qcut15'] = pd.qcut(hist_df['LambdaMax'], q=15, precision=1, labels=False, retbins = False)\n",
    "    plt.hist(hist_df['bin_qcut15'], bins=15)\n",
    "    plt.show()\n",
    "\n",
    "    if x == 0:\n",
    "        wds_class_list = [fiv_list, ten_list, fif_list]\n",
    "        print(wds_class_list)\n",
    "    elif x == 1:\n",
    "        wds_ni_class_list = [fiv_list, ten_list, fif_list]\n",
    "        print(wds_ni_class_list)\n",
    "    else:\n",
    "        rod_class_list = [fiv_list, ten_list, fif_list]\n",
    "        print(rod_class_list)\n",
    "\n",
    "    x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allows for automatic multifacet class assignment during datasplitting\n",
    "def class_assignment(lmax, class_bounds):\n",
    "  #lmax = x[4]\n",
    "  #class_bounds = class_list[splits]\n",
    "  opclass = 0\n",
    "  while opclass < len(class_bounds)-1:\n",
    "    if (round(lmax) > int(class_bounds[opclass]) and round(lmax) <= int(class_bounds[opclass+1])):\n",
    "        return(opclass)\n",
    "      \n",
    "    else:\n",
    "      opclass += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ca392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1: Extract Data From Vizphiz``\n",
    "\n",
    "#3 different 'version' // 'splits' of the raw sequence data \n",
    "wd_output = 'wds.txt'\n",
    "wd_ni_output = 'wds_ni.txt'\n",
    "rod_output = 'rod.txt'\n",
    "\n",
    "#Regular Metadata Files\n",
    "wds_metadata = 'wds_meta.tsv'\n",
    "wd_ni_metadata = 'wds_ni_meta.tsv'\n",
    "rh_metadata = 'rod_meta.tsv'\n",
    "\n",
    "#Classifer Specific Metadata Files\n",
    "class_ni_metadata = ['class_ni_meta_5.tsv','class_ni_meta_10.tsv','class_ni_meta_15.tsv']\n",
    "class_metadata = ['class_meta_5.tsv','class_meta_10.tsv','class_meta_15.tsv']\n",
    "class_rod_metadata = ['class_rod_meta_5.tsv','class_rod_meta_10.tsv','class_rod_meta_15.tsv']\n",
    "\n",
    "invert_counter = 'invert_data.tsv'\n",
    "#class_ranges = 'classifier_ranges.tsv'\n",
    "m = 0\n",
    "s = 0\n",
    "l = 0\n",
    "r = 0\n",
    "c = 0\n",
    "d = re.compile(\"^NM_001014890.2$|^NM_001014890%\")\n",
    "iec = re.compile(\"Limenitis|Papilio\")\n",
    "inv = re.compile('^Rtc|^BRh[0-3]|Pr[A-Z]|Rh1,Rh3|^IV|^inv')\n",
    "acc_list = []\n",
    "duped = 0\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  database=\"vizphiz\",\n",
    "  password=\"Geass5566!!\"\n",
    ") \n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "sql = \"select DISTINCT o.genus,o.species,o.genefamily,o.accession,h.lamdamax, o.aa from opsins.opsins o, opsins.heterologous h WHERE (o.accession = h.accession AND o.refid = h.refid); \"\n",
    "mycursor.execute(sql)\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "class_bounds = ten_list\n",
    "\n",
    "for x in myresult:       \n",
    "\n",
    "  #Keep all accessions in a list -- don't print \n",
    "  if (x[3] in acc_list):\n",
    "    #print (\"\\n\\n\\n****Accession Exists\" + x[2] + \"\\n\\n\" )\n",
    "    duped=1\n",
    "  #First 2 of if statements ignore ancestral (pigment named) or mutated genes\n",
    "  if (duped==1) :\n",
    "    duped=0\n",
    "  #do not print if contains the word \"pigment\" which is an ancestral sequence\n",
    "\n",
    "  else :\n",
    "#REG-DATA SECTION    \n",
    "       with open(wd_output, 'a') as f:\n",
    "          if m == 0:\n",
    "            f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "          if (d.match(x[3]) or (x[4] == 0)):\n",
    "            pass\n",
    "          else:\n",
    "            m += 1 \n",
    "            #This makes the fasta format file\n",
    "            seq = \">S\" + str(m)\n",
    "            f.write(seq)\n",
    "            seq2 = str('\\n' + x[5] + '\\n')\n",
    "            f.write(seq2)\n",
    " \n",
    "       with open(wd_ni_output, 'a') as f:\n",
    "        p = re.compile('^Rtc|^BRh[0-3]|Pr[A-Z]|Rh1,Rh3|^IV|^inv')\n",
    "        if (p.match(x[2]) or d.match(x[3]) or iec.match(x[0]) or (x[4] == 0)):\n",
    "          pass\n",
    "        else:\n",
    "          if c == 0:\n",
    "            f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "\n",
    "          c += 1 \n",
    "          #This makes the fasta format file\n",
    "          seq = \">S\" + str(c)\n",
    "          f.write(seq)\n",
    "          seq2 = str('\\n' + x[5] + '\\n')\n",
    "          f.write(seq2)\n",
    "\n",
    "       with open(rod_output, 'a') as f:\n",
    "\n",
    "        p = re.compile('Rh[0-2]|exoRh')\n",
    "        if p.match(x[2]):\n",
    "          if r == 0:\n",
    "            f.write(\">Bovine\\nMNGTEGPNFYVPFSNKTGVVRSPFEAPQYYLAEPWQFSMLAAYMFLLIMLGFPINFLTLYVTVQHKKLRTPLNYILLNLAVADLFMVFGGFTTTLYTSLHGYFVFGPTGCNLEGFFATLGGEIALWSLVVLAIERYVVVCKPMSNFRFGENHAIMGVAFTWVMALACAAPPLVGWSRYIPEGMQCSCGIDYYTPHEETNNESFVIYMFVVHFIIPLIVIFFCYGQLVFTVKEAAAQQQESATTQKAEKEVTRMVIIMVIAFLICWLPYAGVAFYIFTHQGSDFGPIFMTIPAFFAKTSAVYNPVIYIMMNKQFRNCMVTTLCCGKNPLGDDEASTTVSKTETSQVAPA\\n\")\n",
    "          if (inv.match(x[2]) or d.match(x[3]) or iec.match(x[0]) or (x[4] == 0)):\n",
    "            pass\n",
    "          else:\n",
    "            r+=1\n",
    "            #This makes the fasta format file\n",
    "            seq = \">S\" + str(r)\n",
    "            f.write(seq)\n",
    "            seq2 = str('\\n' + x[5] + '\\n')\n",
    "            f.write(seq2)\n",
    "\n",
    "#CLASS METADATA SECTION          \n",
    "       for splits in range(len(class_metadata)): \n",
    "        with open(class_metadata[splits], 'a') as h:\n",
    "            #This makes the metadata formatted for a classification model. \n",
    "          if m == 1:\n",
    "            h.write(\"\\tOpsin_Class\\n\")\n",
    "            h.write(\"Bovine\\t\" + str(class_assignment(500.000, wds_class_list[splits])) + \"\\n\")\n",
    "          if (d.match(x[3]) or (x[4] == 0)):\n",
    "            pass\n",
    "          else:  \n",
    "            md = \"S\" + str(m) + \"\\t\" + str(class_assignment(x[4], wds_class_list[splits])) + \"\\n\"\n",
    "            h.write(md)\n",
    "\n",
    "        with open(class_ni_metadata[splits], 'a') as h:\n",
    "          p = re.compile('^Rtc|^BRh[0-3]|Pr[A-Z]|Rh1,Rh3|^IV|^inv')\n",
    "          if (p.match(x[2]) or d.match(x[3]) or iec.match(x[0]) or (x[4] == 0)):\n",
    "            pass\n",
    "          else:\n",
    "            if c == 1:\n",
    "              h.write(\"\\tOpsin_Class\\n\")\n",
    "              h.write(\"Bovine\\t\" + str(class_assignment(500.000, wds_ni_class_list[splits])) + \"\\n\")\n",
    "\n",
    "            \n",
    "            md = \"S\" + str(c) + \"\\t\" + str(class_assignment(x[4], wds_ni_class_list[splits])) + \"\\n\"\n",
    "            h.write(md)\n",
    "\n",
    "        with open(class_rod_metadata[splits], 'a') as h:\n",
    "            #This makes the metadata formatted for a classification model. \n",
    "          p = re.compile('Rh[0-3]|exoRh')\n",
    "          if p.match(x[2]):\n",
    "            if r == 1:\n",
    "              h.write(\"\\tOpsin_Class\\n\")\n",
    "              h.write(\"Bovine\\t\" + str(class_assignment(500.000, rod_class_list[splits])) + \"\\n\")\n",
    "            if (inv.match(x[2]) or d.match(x[3]) or iec.match(x[0]) or (x[4] == 0)):\n",
    "              pass\n",
    "            else:  \n",
    "              md = \"S\" + str(r) + \"\\t\" + str(class_assignment(x[4], rod_class_list[splits])) + \"\\n\"\n",
    "              h.write(md)\n",
    "\n",
    "\n",
    "#REGULAR METADATA SECTION\n",
    "       with open(wds_metadata, 'a') as g:\n",
    "        if m == 1:\n",
    "          g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")  \n",
    "          g.write(\"Bovine\\t500\\tBos_tarus.0000\\tRh1\\tNM_001014890\\n\")\n",
    "        if (d.match(x[3]) or x[4] == 0):\n",
    "          pass\n",
    "        else:        \n",
    "          md =  str(\"S\" + str(m) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "          g.write(md)\n",
    "\n",
    "       with open(wd_ni_metadata, 'a') as g:\n",
    "        p = re.compile('^Rtc|^BRh[0-3]|Pr[A-Z]|Rh1,Rh3|^IV|^inv')\n",
    "        if (p.match(x[2]) or d.match(x[3]) or iec.match(x[0]) or (x[4] == 0)):\n",
    "          pass\n",
    "        else:\n",
    "          if c == 1:\n",
    "            g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")\n",
    "            g.write(\"Bovine\\t500.0000\\tBos_tarus\\tRh1\\tNM_001014890\\n\")\n",
    "\n",
    "          md =  str(\"S\" + str(c) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "          g.write(md)\n",
    "\n",
    "       with open(rh_metadata, 'a') as g:\n",
    "        #This makes the metadata formatted for a linear regression model.\n",
    "        p = re.compile('Rh[0-3]|exoRh')\n",
    "\n",
    "        if p.match(x[2]):\n",
    "          if r == 1:\n",
    "            g.write(\"\\tLambda_Max\\tSpecies\\tOpsin_Family\\tAccession\\n\")\n",
    "            g.write(\"Bovine\\t500.0000\\tBos_taurus\\tRh1\\tNM_001014890\\n\")\n",
    "          if (inv.match(x[2]) or d.match(x[3]) or iec.match(x[0]) or (x[4] == 0)):\n",
    "            pass\n",
    "          else:  \n",
    "            md =  str(\"S\" + str(r) + \"\\t\" + str(x[4]).strip()) + \"\\t\" + str(x[0]).strip().replace(' ','') + \"_\" + str(x[1]).strip().replace(' ','') + \"\\t\" + str(x[2]).strip() + \"\\t\" + x[3].strip() + \"\\n\"\n",
    "            g.write(md)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2d97e9b",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 2: Format Alignments for 'deepBreaks'</font>\n",
    "## REMINDER - Take outputs from STEP 1 and run through MAFFT before moving on to STEP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560865c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter list of aligned text files here.\n",
    "inputs = ['wds_aligned.txt','wds_ni_aligned.txt','rod_aligned.txt']\n",
    "##enter list of names for desired formatted fasta files here.\n",
    "output = ['wds_fmt.fasta','wds_ni_fmt.fasta','rod_fmt.fasta']\n",
    "i=0\n",
    "k = 0\n",
    "for files in inputs:\n",
    "    lines = open(inputs[i]).readlines()\n",
    "    file = open(output[i], 'a+')\n",
    "    #line_count = len(lines)\n",
    "    #tab_entry = \"\"\n",
    "    #call = input(\"How Many Lines Per Alignment?: \")\n",
    "    #count = int(call)\n",
    "    #loop = range(int(count))\n",
    "    m=0\n",
    "    for line in lines:\n",
    "        snip = str(lines[k])\n",
    "        if '>' in snip:\n",
    "            if m == 0:\n",
    "                m+=1\n",
    "            else:\n",
    "                file.write(\"\\n\")\n",
    "            file.write(snip)\n",
    "        else:\n",
    "            entry = \"\"\n",
    "            entry = str(snip.replace(\"\\n\",\"\"))\n",
    "            file.write(entry)\n",
    "        k+=1\n",
    "    k = 0\n",
    "    i+=1\n",
    "    file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01e40c92",
   "metadata": {},
   "source": [
    "# <font color=red>STEP 3: deepBreaks</font>\n",
    "## THIS IS A LONG SECTION! \n",
    "### STEP 4 doesn't start until Cell 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4396c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing deepBreaks libraries \n",
    "from deepBreaks.utils import get_models, get_scores, get_params, make_pipeline\n",
    "from deepBreaks.preprocessing import MisCare, ConstantCare, URareCare, CustomOneHotEncoder\n",
    "from deepBreaks.preprocessing import FeatureSelection, CollinearCare\n",
    "from deepBreaks.preprocessing import read_data, balanced_classes\n",
    "from deepBreaks.models import model_compare_cv, finalize_top, importance_from_pipe, mean_importance, summarize_results\n",
    "from deepBreaks.visualization import plot_scatter, dp_plot, plot_imp_model, plot_imp_all\n",
    "import warnings\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f084f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining user params, file pathes, analysis type\n",
    "\n",
    "# path to sequences\n",
    "seqFileName = 'wds_fmt.fasta'\n",
    "meta_data_fileName = 'class_meta_10.tsv'\n",
    "# name of the phenotype\n",
    "mt = 'Opsin_Class'\n",
    "\n",
    "# type of the sequences\n",
    "seq_type = 'aa'\n",
    "# type of the analysis if it is a classification model, then we put cl instead of reg\n",
    "ana_type = 'cl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d592e45d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making a unique directory for saving the reports of the analysis\n",
    "print('direcory preparation')\n",
    "dt_label = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "seqFile = seqFileName.split('.')[0]\n",
    "report_dir = str(seqFile +'_' + mt + '_' + dt_label)\n",
    "os.makedirs(report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0ba03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# importing sequences data\n",
    "print('reading meta-data')\n",
    "# importing metadata\n",
    "meta_data = read_data(meta_data_fileName, seq_type = None, is_main=False)\n",
    "\n",
    "# importing sequences data\n",
    "print('reading fasta file')\n",
    "tr = read_data(seqFileName, seq_type = seq_type, is_main=True, gap_threshold=0.5)\n",
    "\n",
    "tr = tr.merge(meta_data.loc[:, mt],  left_index=True, right_index=True, how='inner')\n",
    "y = tr.loc[:, mt].values\n",
    "tr.drop(mt, axis=1, inplace=True)\n",
    "print('Shape of data is: ', tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fc2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.head()\n",
    "#tr.to_csv(path_or_buf=\"test.csv\",index = False,mode=\"w\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c86759af",
   "metadata": {},
   "source": [
    "**Attention**: metadata and sequences data should have the names as their row names and for each sequence their must be a value in the meta data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('metadata looks like this:')\n",
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca2beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d57dfe28",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "In this step, we do all these steps:\n",
    "1. dropping columns with a number of missing values above a certain threshold  \n",
    "2. dropping zero entropy columns  \n",
    "3. imputing missing values with the mode of that column  \n",
    "4. replacing cases with a frequency below a threshold (default 1.5%) with the mode of that column\n",
    "5. dropping zero entropy columns\n",
    "6. use statistical tests (each position against the phenotype) and drop columns with p-values below a threshold (default 0.25)\n",
    "7. one-hot encode the remaining columns\n",
    "8. calculate the pair-wise distance matrix for all of the columns\n",
    "9. use the distance matrix for DBSCAN and cluster the correlated positions together\n",
    "10. keep only one column (closes to center of each cluster) for each group and drop the rest from the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pipeline = make_pipeline(\n",
    "    steps=[\n",
    "        ('mc', MisCare(missing_threshold=0.15)),\n",
    "        ('cc', ConstantCare()),\n",
    "        ('ur', URareCare(threshold=0.05)),\n",
    "        ('cc2', ConstantCare()),\n",
    "        ('one_hot', CustomOneHotEncoder()),\n",
    "        ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10)),\n",
    "        ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.05))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f04e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "report, top = model_compare_cv(X=tr, y=y, preprocess_pipe=prep_pipeline,\n",
    "                               models_dict=get_models(ana_type=ana_type),\n",
    "                               scoring=get_scores(ana_type=ana_type),\n",
    "                               report_dir=report_dir,\n",
    "                               cv=12, ana_type=ana_type, cache_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0476ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hold = tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pipeline = make_pipeline(\n",
    "    steps=[\n",
    "        ('mc', MisCare(missing_threshold=0.15)),\n",
    "        ('cc', ConstantCare()),\n",
    "        ('ur', URareCare(threshold=0.05)),\n",
    "        ('cc2', ConstantCare()),\n",
    "        ('one_hot', CustomOneHotEncoder()),\n",
    "        ('feature_selection', FeatureSelection(model_type=ana_type, alpha=0.10, keep=True)),\n",
    "        ('collinear_care', CollinearCare(dist_method='correlation', threshold=0.05, keep=True))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87350c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_top = []\n",
    "for model in top:\n",
    "    modified_top.append(make_pipeline(steps=[('prep', prep_pipeline), model.steps[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0567d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_top[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "top = finalize_top(X=tr, y=y, top_models=modified_top, grid_param={},report_dir=report_dir, cv=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f0e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a8510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for model in top:\n",
    "    predictions = model.predict(train_hold)\n",
    "    print(model.score(train_hold, y))\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "    print(cm)\n",
    "    #ConfusionMatrixDisplay.from_predictions(y_true= y, y_pred = predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    title = str(model[1])\n",
    "    title = title.split('(')\n",
    "    disp.ax_.set_title(f\"10 Class WDS - {title[0]} Model\")\n",
    "    disp.ax_.set_ylabel(\"True Class\")\n",
    "    disp.ax_.set_xlabel(\"Predicted Class\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ce41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = 340,360,380,420,450,480,490,495,505,520,560\n",
    "class_means = []\n",
    "i = 0\n",
    "for colors in class_list:\n",
    "#Convert class values to median lambda max value of that class in new column\n",
    "    if i+1 != len(class_list):\n",
    "        mean_lambda = mean([class_list[i],class_list[i+1]])\n",
    "        class_means.append(mean_lambda)\n",
    "        i+=1\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "#print(class_means)\n",
    "\n",
    "class_diffs = []\n",
    "i = 0\n",
    "for means in class_means:\n",
    "    if i+1 != len(class_means):\n",
    "        #if i == 0:\n",
    "            #class_diffs.append(0)\n",
    "        diff_lambda = float(class_means[i+1] - class_means[i])\n",
    "        class_diffs.append(diff_lambda)\n",
    "        i+=1\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "#These will be the weights between classes, and will be additive as the prediction gets further from the ground-truth classification.\n",
    "print(class_diffs)\n",
    "#Will need to make it so weight assignment has a 'row_count' corresponding to the class 'y' value of the ordered pair.\n",
    "class_count = range(len(class_means))\n",
    "#make a set of all possible ordered pair combinations...\n",
    "#(0,0),(0,1),(0,2)....\n",
    "ordered_pairs = []\n",
    "#m will be our'known_class'\n",
    "for m in class_count:\n",
    "    i = 0\n",
    "    while i <= len(class_count)-1:\n",
    "        ordered_pairs.append([i,m])\n",
    "        i+=1\n",
    "print(ordered_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns = [\"Pred_Known\",\"Count\",\"Weight\",\"True_Num\"]\n",
    "results_df = pd.DataFrame(columns=data_columns)\n",
    "results_df.Pred_Known = ordered_pairs\n",
    "results_df.Count = 0 \n",
    "results_df.Weight = 0\n",
    "results_df.True_Num = 0\n",
    "results_df.set_index(\"Pred_Known\")\n",
    "#print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a4f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i=0\n",
    "m=0\n",
    "for row in cm:\n",
    "    for entry in row: \n",
    "        entry = float(entry)\n",
    "        results_df.Count[m] += entry \n",
    "        if results_df.Pred_Known[m][0] == results_df.Pred_Known[m][1]: \n",
    "                        results_df.True_Num[m] += sum(row)\n",
    "\n",
    "        m+=1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb98deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for plot in results_df.Pred_Known:\n",
    "    #iterate through and assign weights to each ordered pair...\n",
    "        #weight = mean confidence score x sum of the differences between means of class range that serpate the prediction from ground truth.\n",
    "    if plot[0] > plot[1]:\n",
    "        i = plot[1]\n",
    "        while i < plot[0]:\n",
    "            results_df.Weight[x] += class_diffs[i]\n",
    "            i+=1\n",
    "    elif plot[0] < plot[1]:\n",
    "        i = plot[0]\n",
    "        while i < plot[1]:\n",
    "            results_df.Weight[x] +=  class_diffs[i]\n",
    "            i+=1          \n",
    "    else:\n",
    "        pass\n",
    "    x+=1\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "whole_matrix = wasserstein_distance(results_df.Count.to_list(),results_df.True_Num.to_list(),results_df.Weight.to_list(),results_df.Weight.to_list())\n",
    "emd = str(whole_matrix)\n",
    "print(emd)\n",
    "\n",
    "#results_df.to_csv(path_or_buf=\"100_iter_matrix.csv\",index = False,mode=\"w\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sr = summarize_results(top_models=top, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f4f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a55733",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot = plot_scatter(summary_result=sr, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ffae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_imp = mean_importance(top, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f07571",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_plot(importance=mean_imp,imp_col='mean', model_name='mean', report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = prep_pipeline[:4].fit_transform(tr)\n",
    "y = le.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced700f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in top:\n",
    "    model_name = model.steps[-1][0]\n",
    "    dp_plot(importance=importance_from_pipe(model),\n",
    "            imp_col='standard_value',\n",
    "            model_name = model_name, report_dir=report_dir)\n",
    "    \n",
    "    plot_imp_model(importance=importance_from_pipe(model), \n",
    "               X_train=tr, y_train=y, model_name=model_name,\n",
    "                   meta_var='meta', model_type=ana_type, report_dir=report_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lgbm = joblib.load('lgbm.pkl') \n",
    "predictions = lgbm.predict(train_hold)\n",
    "print(lgbm.score(train_hold, y))\n",
    "cm = confusion_matrix(y, predictions)\n",
    "print(cm)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true= y, y_pred = predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "disp.ax_.set_title(\"Opsin Prediction - 10 Class Model\")\n",
    "disp.ax_.set_ylabel(\"True Class\")\n",
    "disp.ax_.set_xlabel(\"Predicted Class\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48bb416c",
   "metadata": {},
   "source": [
    "# STEP 3.5: Classification Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = 0\n",
    "val = int(0)\n",
    "data = list()\n",
    "seq_dict = dict()\n",
    "unseenData = 'unseendata.fasta' \n",
    "seq_type2 = 'amino-acid'\n",
    "#Following creates a dataframe of aa sequences and their positions as collumns.\n",
    "#We no longer need to fmt the data past this point, no hot-encoding needed. The model automatically takes care of this. \n",
    "df = prp.read_data(unseenData, seq_type = seq_type2, is_main=True, gap_threshold=0.6)\n",
    "print(df)\n",
    "seq_name = df.index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc622a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "load_lgbm = joblib.load('lg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5087a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=0\n",
    "load_lgbm\n",
    "predictions = load_lgbm.predict(df)\n",
    "print(predictions)\n",
    "prediction_dict = dict()\n",
    "for seqs in seq_name:\n",
    "    prediction_dict.update({seqs : predictions[x]})\n",
    "    x+=1\n",
    "print(prediction_dict)\n",
    "\n",
    "#load_lgbm.predict_proba(tr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e0769b6",
   "metadata": {},
   "source": [
    "# <font color=red>Step 4: Graphing Test Results -</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc5c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as p\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "from statistics import mean\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac28a76b",
   "metadata": {},
   "source": [
    "\n",
    "The Following Code block turns the mean wavelength of the class range into its hex code equivalent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_assignment = \"classifier_ranges.tsv\"\n",
    "classes = pd.read_csv(class_assignment, delimiter='\\t')\n",
    "class_list = []\n",
    "\n",
    "for c in classes['Class_Ranges']:\n",
    "    print(c)\n",
    "    class_list.append(c)\n",
    "    print(class_list)\n",
    "\n",
    "hex_list = []\n",
    "\n",
    "for waves in class_list:\n",
    "    gamma = 0.8\n",
    "    intensity_max = 1\n",
    "    wave = waves\n",
    "    if wave < 380:\n",
    "            red, green, blue = 0, 0, 0\n",
    "    elif wave < 440:\n",
    "        red = -(wave - 440) / (440 - 380)\n",
    "        green, blue = 0, 1\n",
    "    elif wave < 490:\n",
    "        red = 0\n",
    "        green = (wave - 440) / (490 - 440)\n",
    "        blue = 1\n",
    "    elif wave < 510:\n",
    "        red, green = 0, 1\n",
    "        blue = -(wave - 510) / (510 - 490)\n",
    "    elif wave < 580:\n",
    "        red = (wave - 510) / (580 - 510)\n",
    "        green, blue = 1, 0\n",
    "    elif wave < 645:\n",
    "        red = 1\n",
    "        green = -(wave - 645) / (645 - 580)\n",
    "        blue = 0\n",
    "    elif wave <= 780:\n",
    "        red, green, blue = 1, 0, 0\n",
    "    else:\n",
    "        red, green, blue = 0, 0, 0\n",
    "\n",
    "    # let the intensity fall of near the vision limits\n",
    "    if wave < 380:\n",
    "        factor = 0\n",
    "    elif wave < 420:\n",
    "        factor = 0.3 + 0.7 * (wave - 380) / (420 - 380)\n",
    "    elif wave < 700:\n",
    "        factor = 1\n",
    "    elif wave <= 780:\n",
    "        factor = 0.3 + 0.7 * (780 - wave) / (780 - 700)\n",
    "    else:\n",
    "        factor = 0\n",
    "\n",
    "    def f(c):\n",
    "        if c == 0:\n",
    "                return 0\n",
    "        else:\n",
    "                return intensity_max * pow (c * factor, gamma)\n",
    "        \n",
    "    #color = f\"{f(red)},{f(green)},{f(blue)}\"\n",
    "    color = [f(green),f(blue),f(red)] \n",
    "    print(color)\n",
    "    hex = colors.rgb2hex(color, keep_alpha=True)\n",
    "    hex_list.append(hex)\n",
    "\n",
    "print(hex_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab8ee85d",
   "metadata": {},
   "source": [
    "The following code takes a csv of predicitons and plots those predicttions relative to the knowns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"wds_classifier_test_results_t2.csv\"\n",
    "outfile = \"100_iterations_plot\"\n",
    "#https://academo.org/demos/wavelength-to-colour-relationship/\n",
    "\n",
    "#Read data\n",
    "table = pd.read_csv(file, delimiter = ',')\n",
    "\n",
    "#Duplicate predicted class next to change to actual lmax \n",
    "table['Predicted_lmax'] = table.loc[:, 'Predicted_Class']\n",
    "i = 0\n",
    "for colors in class_list:\n",
    "#Convert class values to median lambda max value of that class in new column\n",
    "    if i+1 != len(class_list):\n",
    "        table['Predicted_lmax'] = table['Predicted_lmax'].replace(i,mean([class_list[i],class_list[i+1]]))\n",
    "        i+=1\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "\n",
    "colorby='Score'\n",
    "\n",
    "#2d\n",
    "sns.scatterplot(x='Lambda_Max', y='Predicted_lmax', data=table, edgecolor = 'none', color = 'black', s = 20)\n",
    "plt.xlabel('Known Lambda-max (nm)')\n",
    "plt.ylabel('Predicted Lambda-max (mean of class in nm)')\n",
    "\n",
    "i = 0\n",
    "alpha = 0.05\n",
    "for wavelengths in class_list:\n",
    "    if i+1 < len(hex_list):\n",
    "        print(hex_list[i])\n",
    "        plt.axhspan(class_list[i],class_list[i+1], facecolor=hex_list[i], alpha=0.15)\n",
    "        i+=1\n",
    "    else: \n",
    "        pass\n",
    "    #place colored bands behind plot\n",
    "\n",
    "m = plt.annotate(\"r^2 = {:.3f}\".format(r2_score(table['Lambda_Max'],table['Predicted_lmax'])), (350, 550))\n",
    "print(m)\n",
    "#If no file name show on screen otherwise save pdf\n",
    "if outfile == '' :\n",
    "    plt.show()\n",
    "else:\n",
    "    fileout = outfile + '.pdf'\n",
    "    plt.savefig(fileout)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff7ece12",
   "metadata": {},
   "source": [
    "# <font color=red>Step 6: Earth Movers Distance (EMD) of Test Results -</font>\n",
    "The following code blocks take results from the 100 iterations test and calculates the EMD between the observed and idealized results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bcb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cce317af",
   "metadata": {},
   "source": [
    "Input for EMD calculator is the list of class boundaries and the results csv from the 100 iterations test...\n",
    "Use this metric to calc a p-value by doing various data perturbations...\n",
    "OR\n",
    "Use to compare the performance of different models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56af12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = 340,360,380,420,450,480,490,495,505,520,560\n",
    "class_means = []\n",
    "i = 0\n",
    "for colors in class_list:\n",
    "#Convert class values to median lambda max value of that class in new column\n",
    "    if i+1 != len(class_list):\n",
    "        mean_lambda = mean([class_list[i],class_list[i+1]])\n",
    "        class_means.append(mean_lambda)\n",
    "        i+=1\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "#print(class_means)\n",
    "\n",
    "class_diffs = []\n",
    "i = 0\n",
    "for means in class_means:\n",
    "    if i+1 != len(class_means):\n",
    "        #if i == 0:\n",
    "            #class_diffs.append(0)\n",
    "        diff_lambda = float(class_means[i+1] - class_means[i])\n",
    "        class_diffs.append(diff_lambda)\n",
    "        i+=1\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "#These will be the weights between classes, and will be additive as the prediction gets further from the ground-truth classification.\n",
    "print(class_diffs)\n",
    "#Will need to make it so weight assignment has a 'row_count' corresponding to the class 'y' value of the ordered pair.\n",
    "class_count = range(len(class_means))\n",
    "#make a set of all possible ordered pair combinations...\n",
    "#(0,0),(0,1),(0,2)....\n",
    "ordered_pairs = []\n",
    "#m will be our'known_class'\n",
    "for m in class_count:\n",
    "    i = 0\n",
    "    while i <= len(class_count)-1:\n",
    "        ordered_pairs.append([i,m])\n",
    "        i+=1\n",
    "#print(ordered_pairs)\n",
    "iter_res = open(\"wds_classifier_test_results_t2.csv\", \"r\",)\n",
    "results_csv = csv.reader(iter_res, delimiter=\",\")\n",
    "data_columns = [\"Pred_Known\",\"Count\",\"Weight\",\"Score\",\"True_Num\"]\n",
    "results_df = pd.DataFrame(columns=data_columns)\n",
    "results_df.Pred_Known = ordered_pairs\n",
    "results_df.Count = 0 \n",
    "results_df.Score = 0\n",
    "results_df.Weight = 0\n",
    "results_df.True_Num = 0\n",
    "results_df.set_index(\"Pred_Known\")\n",
    "#print(results_df)\n",
    "x = 0\n",
    "for entry in results_csv:\n",
    "    if x == 0:\n",
    "        x+=1\n",
    "    else:\n",
    "        pair = [int(entry[2]),int(entry[1])]\n",
    "        i = 0\n",
    "        for plot in results_df.Pred_Known:\n",
    "            if plot[0] == pair[0] and plot[1] == pair[1]:\n",
    "                results_df.Count[i]+= 1\n",
    "                results_df.Score[i] += float(entry[4])\n",
    "                m = 0\n",
    "                for s in results_df.Pred_Known:\n",
    "                    if s[1] == pair[1] and s[0] == s[1]: \n",
    "                        results_df.True_Num[m] += 1 \n",
    "                    m+=1\n",
    "            i+=1\n",
    "    \n",
    "\n",
    "x = 0\n",
    "for score in results_df.Score:\n",
    "    if score == 0:\n",
    "        results_df.Score[x] = 0.000\n",
    "    else:\n",
    "        score = score / results_df.Count[x]\n",
    "        results_df.Score[x] = score\n",
    "\n",
    "    x+=1\n",
    "#print(results_df)\n",
    "\n",
    "x = 0\n",
    "for plot in results_df.Pred_Known:\n",
    "    #iterate through and assign weights to each ordered pair...\n",
    "        #weight = mean confidence score x sum of the differences between means of class range that serpate the prediction from ground truth.\n",
    "    if plot[0] > plot[1]:\n",
    "        i = plot[1]\n",
    "        while i < plot[0]:\n",
    "            results_df.Weight[x] += class_diffs[i] * results_df.Score[x]\n",
    "            i+=1\n",
    "    elif plot[0] < plot[1]:\n",
    "        i = plot[0]\n",
    "        while i < plot[1]:\n",
    "            results_df.Weight[x] +=  class_diffs[i] * results_df.Score[x] \n",
    "            i+=1          \n",
    "    else:\n",
    "        pass\n",
    "    x+=1\n",
    "print(results_df)\n",
    "\n",
    "whole_matrix = wasserstein_distance(results_df.Count.to_list(),results_df.True_Num.to_list(),results_df.Weight.to_list(),results_df.Weight.to_list())\n",
    "emd = str(whole_matrix)\n",
    "print(emd)\n",
    "\n",
    "results_df.to_csv(path_or_buf=\"100_iter_matrix.csv\",index = False,mode=\"w\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepBreaks_altenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1566c31c90cd32f196ccfa15812cd8e8608767ea4549b0419bac2fea141e189a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
